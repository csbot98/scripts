#!/usr/bin/env python3
import base64
import json
import requests
import aiohttp
import asyncio
import re
import os
import smtplib
import logging
import sys
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from elasticsearch8 import Elasticsearch #9v-el is m√ºk≈ëdik, de ha k√©s≈ëbb update sor√°n nem menne a script, c√©lszer≈± √∫jabbb elk modult telep√≠teni.
from datetime import datetime

# -----------------------------
# ----- Global Settings --
# -----------------------------
###Hibakezel√©s miatt ker√ºlt be. F√°jlba/Konzolra √≠rja az inf√≥kat. (Default: True)
debug_mode = False
###Hibakezel√©s miatt ker√ºlt be, "False" eset√©n nem ker√ºl be a SOAR-ba az adat. (Default: True)
send_to_soar = True
#Payload ki√≠rat√°sa (Default: False)
payloads_to_console= False
payloads_to_file=False

# Config (ide tedd be k√ºls≈ë f√°jlb√≥l is ak√°r)
es_host = "https://1.1.1.1:1111"
es_user = "user"
es_pass = "password"

# Index neve (Opcion√°lisan cser√©lhet≈ë)
es_index = ".internal.alerts-security.alerts-default-*"

#SOAR info
soar_host = "2.2.2.2"
soar_url= "https://2.2.2.2/#incidents?presetId=-1"
api_key_id = "APIKEYID"
api_key_secret = "APIKEYSECRET"
org_id = "201"

#Email info
smtp_server = "3.3.3.3"
smtp_port = 25
sender_email = "sender@yourdomain.com" 
to_email="receiver@yourdomain.com"

# Teams URL
webhook_url ="WEBHOOKAPI"

###Logging
logger = logging.getLogger()
logger.setLevel(logging.DEBUG)

console_handler = logging.StreamHandler()
console_handler.setLevel(logging.DEBUG)  # Alap√©rtelmezett szint, minden √ºzenetet ki√≠r a konzolra

# Handler a f√°jlba (csak ERROR √©s CRITICAL szint≈± √ºzenetek)
error_file_handler = logging.FileHandler('elk_script_error.log')
error_file_handler.setLevel(logging.ERROR)  # Csak ERROR √©s ann√°l s√∫lyosabb √ºzenetek

# Formatterek be√°ll√≠t√°sa
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
console_handler.setFormatter(formatter)
error_file_handler.setFormatter(formatter)

# Handlerek hozz√°ad√°sa a loggerhez
logger.addHandler(console_handler)
logger.addHandler(error_file_handler)

# -----------------------------
# ----- Functions ----------
# -----------------------------
    
    ##########################
      # Connect to Elastic #
    ##########################
async def connect_to_elasticsearch():
    es_client = Elasticsearch(
        es_host,
        basic_auth=(es_user, es_pass),
        verify_certs=False
    )
    return es_client
    
            #############################
              # Teams Report Part#
            #############################
            
    #############################
      # Send Report via Teams #
    #############################
stats = {
    "successful_incidents": 0,
    "failed_incidents": 0,
    "duplicates": 0,
    "artifacts_created": 0,
    "datatable_rows_added": 0,
}

def reset_stats():
    #Null√°zza a statisztik√°kat a k√∂vetkez≈ë id≈ëszakhoz.
    global stats
    stats = {
        "successful_incidents": 0,
        "failed_incidents": 0,
        "artifacts_created": 0,
        "datatable_rows_added": 0,
    }

def update_stats(successful=0, failed=0, duplicates=0, artifacts=0, datatable_rows=0):
    #Friss√≠ti a glob√°lis statisztik√°kat.
    global stats
    stats["successful_incidents"] += successful
    stats["failed_incidents"] += failed
    stats["duplicates"] += duplicates
    stats["artifacts_created"] += artifacts
    stats["datatable_rows_added"] += datatable_rows

def create_teams_message():
    #√ñssze√°ll√≠tja a Teams √ºzenet payload-j√°t a jelenlegi statisztik√°k alapj√°n.
    message_text = (
        f"<strong>Incidens riport:</strong><br>"
        f"‚Ä¢ Gener√°lt incidensek sz√°ma: {stats['successful_incidents']}<br>"
        f"‚Ä¢ Hozz√°adott artifactok sz√°ma: {stats['artifacts_created']}<br>"
        f"‚Ä¢ Hozz√°adott Data Table sorok sz√°ma: {stats['datatable_rows_added']}<br>"
        f"‚Ä¢ Sikertelen incidens gener√°l√°sok sz√°ma: {stats['failed_incidents']}"
    )
    payload = {
        "text": message_text
    }
    return payload

def reset_stats():
    for key in stats:
        stats[key] = 0

def send_teams_report(webhook_url: str):
    #Elk√ºldi a riportot Teams webhookon kereszt√ºl.
    payload = create_teams_message()

    try:
        response = requests.post(webhook_url, json=payload)
        
        if response.status_code == 200:
            if debug_mode:
                logger.debug("Teams riport sikeresen elk√ºldve.")
            reset_stats()  # Null√°zzuk a statisztik√°kat a k√∂vetkez≈ë id≈ëszakhoz
        else:
            text = response.text
            logger.error(f"Hiba a Teams riport k√ºld√©sekor: {response.status_code} - {text}")
    
    except Exception as e:
        logger.error(f"Hiba t√∂rt√©nt a Teams riport k√ºld√©se k√∂zben: {e}")
    
            ##################################
              #End of the Teams Report Part#
            ##################################

    ######################################
      # Load group.id values from file # 
    ######################################    
# F√ºggv√©ny, amely bet√∂lti a feldolgozott group.id-ket a f√°jlb√≥l
def load_processed_group_ids(file_path="processed_group_ids.txt"):
    if os.path.exists(file_path):
        with open(file_path, "r") as file:
            return set(line.strip() for line in file)
    return set()

# F√ºggv√©ny, amely appendel egy √∫j group.id-t a f√°jlhoz
def append_group_id_to_file(group_id, file_path="processed_group_ids.txt"):
    with open(file_path, "a") as file:
        file.write(f"{group_id}\n")

# F√ºggv√©ny, amely menti a friss√≠tett group.id-ket a f√°jlba
def save_processed_group_ids(processed_group_ids, file_path="processed_group_ids.txt"):
    # Ha a f√°jl l√©tezik, akkor beolvassuk, hogy ne t√°roljunk duplik√°lt group.id-kat
    existing_group_ids = load_processed_group_ids(file_path)
    
    # Csak az √∫j, m√©g nem l√©tez≈ë group.id-ket adjuk hozz√°
    new_group_ids = processed_group_ids - existing_group_ids
    
    # Ha van √∫j group.id, akkor hozz√°adjuk ≈ëket a f√°jlhoz
    if new_group_ids:
        with open(file_path, "a") as file:
            for group_id in new_group_ids:
                file.write(f"{group_id}\n")
    else:
        if debug_mode:
            logger.debug("Nincs √∫j group.id a ment√©shez.")
        
processed_group_ids = load_processed_group_ids()

# Ha nem tal√°lunk f√°jlt, akkor inicializ√°lunk egy √ºres halmazt
if not processed_group_ids:
    processed_group_ids = set()

    
    ##########################
      # Search doc from ES #
    ##########################
async def search_documents_from_es(es_host, index, query_body, size=100, filename="elk_results.txt"):
    try:
        # Az Elasticsearch URL-je
        url = f"{es_host}/{index}/_search"
        headers = {
            "Content-Type": "application/json"
        }
        auth = aiohttp.BasicAuth(es_user, es_pass)
        query_body["size"] = size
        # Aszinkron HTTP kapcsolat l√©trehoz√°sa
        async with aiohttp.ClientSession() as session:
            async with session.post(url, json=query_body, headers=headers, auth=auth, verify_ssl=False) as response:
                # Ha a v√°lasz sikeres (HTTP 200)
                if response.status == 200:
                    data = await response.json()
                    hits = data["hits"]["hits"]

                    # Debug m√≥d enged√©lyez√©se eset√©n
                    if debug_mode:
                        logger.debug(f"DEBUG MODE: ‚úÖ Elasticsearch keres√©si tal√°latok sz√°ma: {len(hits)}")
                        if payloads_to_console:
                            for hit in hits:
                                print(json.dumps(hit["_source"], indent=2, ensure_ascii=False))

                    # Ha sz√ºks√©ges, a tal√°latok f√°jlba ment√©se
                    if debug_mode and payloads_to_file:
                        with open(filename, 'w', encoding='utf-8') as file:
                            json.dump(hits, file, indent=2, ensure_ascii=False)
                            print(f"‚úîÔ∏è Az adatokat sikeresen elmentett√ºk a '{filename}' f√°jlba.")

                    return hits
                else:
                    raise Exception(f"Elasticsearch k√©r√©s hiba: {response.status}")
    except Exception as e:
        raise RuntimeError(f"Hiba az Elasticsearch keres√©sn√©l: {e}")

    ####################
      # SOAR Connect #
    ####################
def get_soar_headers():
    auth = f"{api_key_id}:{api_key_secret}"
    encoded_auth = base64.b64encode(auth.encode()).decode()
    return {
        "Content-Type": "application/json",
        "Authorization": "Basic " + encoded_auth
    }

    #######################################
      # Check SIEM Rule Name with Query #
    #######################################
def build_query_with_rule_name_check(prefix="TRI_", tags=["tri", "TRI"]):
    return {
        "query": {
            "bool": {
                "should": [  # "should" = vagy-vagy kapcsolat
                    {
                        "wildcard": {
                            "kibana.alert.rule.name": {
                                "value": f"{prefix}*"
                            }
                        }
                    },
                    {
                        "terms": {
                            "kibana.alert.rule.tags": tags  # "tri/TRI" tag keres√©se
                        }
                    }
                ],
                "minimum_should_match": 1  # Legal√°bb egy felt√©telnek teljes√ºlnie kell
            }
        },
        "sort": [
            {
                "kibana.alert.original_event.ingested": {
                    "order": "desc"
                }
            }
        ]
    }
        
    #######################################
      # Check group.id #
    #######################################
def classify_hit_by_group_id(hit):
    #Megvizsg√°lja, hogy van-e group.id:
        #Ha van √©s egyenl≈ë az adott log alert.id-val, akkor = incidens lesz bel≈ële
        #Ha nincs group.id, akkor is incidens lesz bel≈ële
        #Ha van √©s nem egyenl≈ë, akkor data table adat lesz bel≈ële √©s nem incidens!
    doc = hit["_source"]
    alert_id = hit["_id"]
    group_id = doc.get("kibana.alert.group.id")

    if not group_id:
        return "incident"
    elif group_id == alert_id:
        return "incident"
    else:
        return "datatable"


    ###############################
      # Create payload from doc #
    ###############################
def create_payload_from_doc(doc, hit, alert_id=None):
    
    index_name = hit["_index"]  # Lek√©rj√ºk az index nev√©t
    alert_id = hit["_id"]  # Lek√©rj√ºk az alert ID-t
    
    rule_name = doc.get("kibana.alert.rule.name", "Unknown Rule")
    hostname = doc.get("host", {}).get("hostname", "No hostname")
    ip_address = doc.get("host", {}).get("ip", [])[0]
    severity = doc.get("kibana.alert.severity", "Low")  # Alap√©rtelmezett "Low", ha nincs √©rt√©k
    message = doc.get("kibana.alert.reason", "Unknown")
    alert_url = doc.get("kibana.alert.url", "No Alert URL")
    event_ingested = doc.get("kibana.alert.original_event.ingested", "No time for this event")
    group_id = doc.get("kibana.alert.group.id.", "No Alert Group ID")
    
    # Le√≠r√°s elk√©sz√≠t√©se
    description = (
        f"SIEM Rule: {rule_name}\n"
        f"Hostname: {hostname}\n"
        f"Severity: {severity}\n"
        #f"Alert Group ID: {group_id}\n"    #Ez kinda felesleges. A group.id megegyezik az alert.id-val, a f≈ë alert eset√©n. Mell√©k alert eset√©n meg nem kre√°l√≥dik incidens.
        f"Message: {message}\n"
        f"Event ingested: {event_ingested}\n"
        f"ELK Index name: {index_name}\n"
        f"ELK Alert ID: {alert_id}\n"
        f"ELK Alert URL: {alert_url}"
    )

    severity_map = {
    "low": "Low",
    "medium": "Medium",
    "high": "High"
    }

    #SOAR-ban nincs "Critical" severity, csak "High", √≠gy a lek√©rt adat relev√°ns r√©sz√©t m√≥dos√≠tjuk.
    severity = "high" if severity == "critical" else severity
    severity_code = severity_map.get(severity.lower(), "Low")

    payload = {
        "name": f"ELK Incident: {rule_name} - {ip_address}",
        "description": description.strip(),
        "severity_code": severity_code,
        "discovered_date": int(datetime.now().timestamp() * 1000)
        #"incident_type_ids": [incident_type_id]
    }

    return payload

    #################################
      # Create artifacts from doc #
    #################################
def extract_artifacts_from_doc(doc):
    artifacts = []
    #Ha defini√°ljuk a t√∂mb elemeit, hogy pontosan mikre lesz sz√ºks√©g, akkor majd ezt m√≥dos√≠tani/√©les√≠teni lehet.
    ##A kinyerend≈ë mez≈ëk list√°ja √©s hozz√°juk tartoz√≥ metaadatok
    keys_to_check = [
        {"path": ["host", "ip"], "type": "IP Address", "description": "IP c√≠m a SIEM alertb≈ël"}, #kiszedi az ipv4/6-ot is egyszer
        {"path": ["host", "hostname"], "type": "String", "description": "Hostname a SIEM alertb≈ël"}
        #{"path": ["network", "domain"], "type": "Domain", "description": "Domain n√©v a logb√≥l"},
        #{"path": ["file", "name"], "type": "File Name", "description": "F√°jln√©v a SIEM alertb≈ël"},
        #{"path": ["host", "mac"], "type": "MAC Address", "description": "MAC c√≠m a hostb√≥l"},
        # Itt b≈ëv√≠thet≈ë tov√°bb m√°s mez≈ëkkel
    ]

    for key_info in keys_to_check:
        # Bej√°rja a megadott "√∫tvonalat" a doc-on bel√ºl
        data = doc
        for k in key_info["path"]:
            data = data.get(k, None)
            if data is None:
                break

        # Ha adat van √©s az lista, akkor vegy√ºk az els≈ët
        if data:
            if isinstance(data, list):
                for value in data:
                    artifacts.append({
                        "type": key_info["type"],
                        "value": value,
                        "description": key_info["description"]
                    })
            else:
                artifacts.append({
                    "type": key_info["type"],
                    "value": data,
                    "description": key_info["description"]
                })
                
    return artifacts

    ######################################
      # Search Doc by "group.id" # 
    ######################################    
async def search_documents_by_group_id(es_host, index, group_id, size=100):
    query = {
        "query": {
            "term": {
                "kibana.alert.group.id": group_id
            }
        },
        "size": size
    }
    return await search_documents_from_es(es_host, index, query)
    
    ######################################
      # SOAR Incident description trim#
    ######################################
def extract_alert_id_from_description(description):
    # Felt√©telezz√ºk, hogy az alert ID az 'ELK Alert ID' kulcssz√≥ ut√°n k√∂vetkezik
    if "ELK Alert ID:" in description:
        # A split seg√≠ts√©g√©vel kinyerj√ºk az alert id-t
        parts = description.split("ELK Alert ID:")
        if len(parts) > 1:
            return parts[1].split("\n")[0].strip()  # Az alert ID a k√∂vetkez≈ë sorban
    return None

    #######################################
      # Get existing Alert ID from SOAR #
    #######################################
async def get_soar_alert_ids(alert_id):
    query_payload = {
        "filters": [
            {
                "conditions": [
                    {
                        "field_name": "description",
                        "method": "contains",
                        "value": alert_id
                    }
                ]
            }
        ],
        "start": 0,
        "length": 100  # P√©ld√°ul 100 tal√°lat lek√©r√©se
    }

    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"https://{soar_host}/rest/orgs/{org_id}/incidents/query_paged",
                headers=get_soar_headers(),
                data=json.dumps(query_payload),
                ssl=False
            ) as response:
                response.raise_for_status()
                result = await response.json()
                soar_alert_ids = []

                for incident in result.get("data", []):
                    desc = incident.get("description", "")
                    # Kinyerj√ºk az alert_id-t a description-b√≥l
                    soar_alert_id = extract_alert_id_from_description(desc)
                    if soar_alert_id:
                        soar_alert_ids.append(soar_alert_id)  # Csak az alert_id-kat t√°roljuk
                return soar_alert_ids
    except Exception as e:
        logger.error(f"Hiba a SOAR lek√©rdez√©s√©n√©l: {e}")
        return []

    ####################################
      # Check if the incident exists #
    ####################################
async def check_if_alert_exists(alert_id):
    soar_alert_ids = await get_soar_alert_ids(alert_id)
    # Megn√©zz√ºk, hogy b√°rmelyik SOAR description tartalmazza-e az alert_id-t
    for soar_alert_id in soar_alert_ids:
        if alert_id in soar_alert_id:
            return True
    return False

    ##############################################################################
      # Extract Incident ID from the SOAR response after sending the payload #
    ##############################################################################
async def extract_incident_id(response):
    try:
        response_data = await response.json()
        incident_id = response_data.get("id")
        if incident_id:
            return incident_id
        else:
            if debug_mode:
                logger.debug("‚ö†Ô∏è Az incident ID nem tal√°lhat√≥ a v√°laszban.")
            return None
    except Exception as e:
        logger.error(f"‚ùå Hiba az incident ID kinyer√©sekor: {e}")
        return None


    #############################
      # Send incident to SOAR #
    #############################
async def send_incident_to_soar(payload):
    if not send_to_soar:
        logger.info("üîï SOAR k√ºld√©s letiltva (send_to_soar = False)")
        return {"skipped": True}  # vagy return "disabled", ha az egyszer≈±bb

    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"https://{soar_host}/rest/orgs/{org_id}/incidents",
                headers=get_soar_headers(),
                data=json.dumps(payload),
                ssl=False
            ) as response:
                response_data = await response.json()

                if response.status in [200, 201]:
                    logger.info("‚úÖ Incidens l√©trehozva.")
                    return response_data
                else:
                    logger.error(f"‚ùå Sikertelen SOAR incident l√©trehoz√°s (HTTP {response.status})")
                    return None
    except Exception as e:
        logger.error(f"‚ùå Hiba a SOAR incident k√ºld√©s√©n√©l: {e}")
        return None


    ##############################################
      #  Send table data to the new incident #
    #############################################
async def add_row_to_soar_datatable(incident_id, doc):
    if not send_to_soar:
        if debug_mode:
            logger.debug("üîï SOAR Data Table friss√≠t√©s letiltva (send_to_soar = False)")
        return
        
    hostname = doc.get("host", {}).get("hostname", "N/A")
    ip_list = doc.get("host", {}).get("ip", [])
    ip_address = ip_list[0] if ip_list else "N/A"
    event_name = doc.get("kibana.alert.rule.name", "Unknown Event")
    message = doc.get("message", "No message")
    event_action= doc.get("event.action", "Unknown Action")
    event_outcome= doc.get("event.outcome", "Unknown Outcome")
    alert_url = doc.get("kibana.alert.url", "No Alert URL")
    #Ezt m√©g tov√°bbi mez≈ëkkel kell kieg√©sz√≠teni.

    # --- Sor adatai a t√°bla mez≈ëi alapj√°n ---
    row_data = {      
        "cells": {
            "event_name": {"value": event_name},
            "hostname": {"value": hostname},
            "source_ip": {"value": ip_address},
            "destination_ip": {"value": "-"},
            "message": {"value": message},
            "event_action": {"value": event_action},
            "event_outcome": {"value": event_outcome},
            "elk_alert_url": {"value": alert_url}
            #Tov√°bbi oszlopok kre√°l√°sa a t√°bl√°ban SOAR UI oldalon!
        }
       }

    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"https://{soar_host}/rest/orgs/{org_id}/incidents/{incident_id}/table_data/event_information/row_data",
                headers=get_soar_headers(),
                data=json.dumps(row_data),
                ssl=False
            ) as response:
                if response.status in [200, 201]:
                    if debug_mode:
                        logger.debug(f"Sor sikeresen hozz√°adva a 'Data Table' t√°bl√°hoz (incident ID: {incident_id})")
                else:
                    logger.error(f"Hiba a sor hozz√°ad√°sakor. St√°tusz: {response.status}")
                    logger.error(await response.text())
    except Exception as e:
        logger.error(f"Kiv√©tel t√∂rt√©nt a Data Table friss√≠t√©s sor√°n: {e}")


    #####################
      # Debug BANNER #
    #####################
def log_debug_banner():
    if debug_mode:
        print("########################")
        print("########################")
        logger.debug("## DEBUG MODE is True ##")
        print("########################")
        print("########################")

    #####################
      # DEBUG Output # Ez jelenleg nincs be√©p√≠tve j√≥l, k√©s≈ëbb ha lesz hozz√° kedvem megoldom, am√∫gy meg nem SOS.
    #####################
# def handle_debug_output(payload, artifacts, alert_id, doc):
    # if debug_mode:
        # if not send_to_soar:
            # print("üö´ SOAR-ba k√ºld√©s le van tiltva (send_to_soar = False).")
            # if payloads_to_console:
                # print("üßæ K√ºldend≈ë payload a SOAR-ba:")
                # print(json.dumps(payload, indent=2, ensure_ascii=False))
            # filename = "soar_payloads.txt"
            # if payloads_to_file: 
                # with open(filename, 'a', encoding='utf-8') as file:
                    # json.dump({
                        # "payload": payload,
                        # "artifacts": artifacts,
                        # "alert_id": alert_id
                    # }, file, indent=2, ensure_ascii=False)
                    # file.write("\n")
                # print(f"‚úîÔ∏è A SOAR payload sikeresen elmentve a '{filename}' f√°jlba.")
            # print(doc)

    ###############################
      # Processes a single hit # 
    ###############################
group_id_to_incident_id = {}
    
async def process_hit(hit):
    global processed_group_ids, group_id_to_incident_id

    doc = hit["_source"]
    alert_id = hit["_id"]
    group_id = doc.get("kibana.alert.group.id")
    classification = classify_hit_by_group_id(hit)

    soar_alert_ids = await get_soar_alert_ids(alert_id)

    if classification == "incident":
        if group_id and group_id not in processed_group_ids:
            processed_group_ids.add(group_id)

            group_hits = await search_documents_by_group_id(es_host, es_index, group_id)
            payload = create_payload_from_doc(doc, hit)
            artifacts = extract_artifacts_from_doc(doc)
            if artifacts:
                payload["artifacts"] = artifacts

            result = await handle_payload_sending(alert_id, payload)

            if result == 'duplicate':
                # Ha duplik√°lt, csak n√∂velj√ºk a 'duplicates' statot
                update_stats(duplicates=1)
            elif result:
                # Ha siker√ºlt l√©trehozni az incidentet
                group_id_to_incident_id[group_id] = result
                datatable_row_count = 0
                tasks = []
                for group_hit in group_hits:
                    group_doc = group_hit["_source"]
                    tasks.append(add_row_to_soar_datatable(result, group_doc))
                await asyncio.gather(*tasks)
                datatable_row_count += len(group_hits)
                update_stats(successful=1, artifacts=len(artifacts), datatable_rows=datatable_row_count)
                
            else:
                # Ha nem siker√ºlt l√©trehozni az incidentet
                update_stats(failed=1)

            append_group_id_to_file(group_id)
        return

    elif classification == "datatable":
        if group_id in group_id_to_incident_id:
            incident_id = group_id_to_incident_id[group_id]
            await add_row_to_soar_datatable(incident_id, doc)
            update_stats(datatable_rows=1)
        else:
            if debug_mode:
                logger.debug(f"group.id ({group_id}) nem tal√°lhat√≥ az incident mappingben. Data table hozz√°ad√°s kihagyva.")

    ########################################
      # Processes every hit individually #
    ########################################
async def process_hits(hits):
    incident_hits = []
    datatable_hits = []

    for hit in hits:
        classification = classify_hit_by_group_id(hit)
        if classification == "incident":
            incident_hits.append(hit)
        elif classification == "datatable":
            datatable_hits.append(hit)
    # 1. Incident t√≠pus√∫ feldolgoz√°s
    await asyncio.gather(*(process_hit(hit) for hit in incident_hits))

    # 2. DataTable sorok feldolgoz√°sa
    await asyncio.gather(*(process_hit(hit) for hit in datatable_hits))
    
######################################
      # Send payload/incident to SOAR #
    ######################################
async def handle_payload_sending(alert_id, payload):
    soar_alert_ids = await get_soar_alert_ids(alert_id)

    if alert_id in soar_alert_ids:
        if debug_mode:
            logger.debug(f"‚ö†Ô∏è Incident m√°r l√©tezik SOAR-ban alert_id alapj√°n: '{alert_id}'. K√ºld√©s kihagyva.")
        return "duplicate"  # M√°r l√©tezett

    # K√ºld√©s a SOAR-ba csak ha enged√©lyezett
    response = await send_incident_to_soar(payload)

    if isinstance(response, dict):
        if response.get("skipped"):
            #logger.debug("üü° SOAR k√ºld√©s kihagyva (send_to_soar = False)")
            return "disabled"

        incident_id = response.get("id")

        if debug_mode:
            logger.debug("DEBUG: SOAR v√°lasz (incident l√©trehozva):")
            if payloads_to_console:
                print(json.dumps(response, indent=2))
        return incident_id

    else:
        logger.error(f"‚ùå Hiba t√∂rt√©nt az incidens l√©trehoz√°sakor! V√°lasz: {response}")
        return None

            
    ########################################
      # Customized HTML body #
    ########################################
def generate_html_body():
    return f"""
    <html>
        <body>
            <h1 style="color: blue;">Reggeli Jelent√©s</h1>
            <p>Ez az automatikusan k√ºld√∂tt <strong>HTML form√°zott</strong> email!</p>
            <h2>Gener√°lt incidensek sz√°ma: {stats['successful_incidents']}</h2>
            <p>‚Ä¢ Hozz√°adott artifactok sz√°ma: {stats['artifacts_created']}</p>
            <p>‚Ä¢ Hozz√°adott Data Table sorok sz√°ma: {stats['datatable_rows_added']}</p>
            <p>‚Ä¢ Sikertelen incidens gener√°l√°sok sz√°ma: {stats['failed_incidents']}</p>
            <a href="{soar_url}">Kattints ide a tov√°bbi r√©szletekhez!</a>
        </body>
    </html>
    """
    
    ########################################
      # Email Notify #
    ########################################
def send_email(subject, body, to_email):
    # E-mail √ºzenet l√©trehoz√°sa
    message = MIMEMultipart("alternative")
    message["From"] = sender_email
    message["To"] = to_email
    message["Subject"] = subject

    # HTML tartalom hozz√°ad√°sa a lev√©lhez
    html_body = generate_html_body()
    message.attach(MIMEText(html_body, 'html'))

    try:
        with smtplib.SMTP(smtp_server, smtp_port) as server:
            server.starttls()
            server.sendmail(sender_email, to_email, message.as_string())
            if debug_mode:
                logger.info(f"Email successfully sent to {to_email} with subject: {subject}")
    except Exception as e:
        logger.error(f"Error occurred while sending email: {e}")

# ----------------------------- #
# ----- Main v√©grehajt√°s ------ #
# ----------------------------- #
async def main():
    log_debug_banner()

    es = await connect_to_elasticsearch()
    query = build_query_with_rule_name_check()
    hits = await search_documents_from_es(es_host, es_index, query, size=100)

    await process_hits(hits)  # Aszinkron feldolgoz√°s
    ##Ha nem akarjuk id≈ëh√∂z k√∂tni a riport k√ºld√©st, akkor csak "uncomment" az al√°bbit.
    # send_email(
            # subject="Reggeli jelent√©s",
            # body=generate_html_body(),
            # to_email=to_email
        # )
    # send_teams_report(webhook_url)
    
    now = datetime.now()
    # Ha √©pp 09:00-kor fut, vagy mondjuk 10:00-10:09 k√∂z√∂tt (mivel 10 percenk√©nt fut)    
    if now.hour == 10 and now.minute < 10:
        send_email(
            subject="Reggeli jelent√©s",
            body=generate_html_body(),
            to_email=to_email
        )
        send_teams_report(webhook_url)
        sys.exit()
        
if __name__ == "__main__":
    asyncio.run(main())  # Aszinkron main futtat√°sa
